# -*- coding: utf-8 -*-
"""Brain Tumor Detection

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1ybv37VPOK121EOMplPEgMx5X-JomOhw9
"""

!pip install pandasql

# Mount google Drive
from google.colab import drive
from pandasql import sqldf
import pandas as pd

drive.mount('/content/drive')

from tensorflow.keras.preprocessing.image import ImageDataGenerator
import matplotlib.pyplot as plt
import numpy as np

datagen = ImageDataGenerator(  rescale=1./255)

# load and iterate training dataset
train_it = datagen.flow_from_directory('/content/drive/MyDrive/BTProject/train/',target_size= (180,218), color_mode= "grayscale", classes= ['no','yes'], class_mode='binary', batch_size=1)
# load and iterate validation dataset
val_it = datagen.flow_from_directory('/content/drive/MyDrive/BTProject/validation/',target_size= (180,218), color_mode= "grayscale", classes= ['no','yes'], class_mode='binary', batch_size=1)

# load and iterate test dataset
test_it = datagen.flow_from_directory('/content/drive/MyDrive/BTProject/test/',target_size= (180,218), color_mode= "grayscale", classes= ['no','yes'], class_mode='binary', batch_size=1)

train_it

range(len(train_it))

type(train_it)

type(train_it[0][1])

#for x in train_it:
 # print(x)

x_train = []
y_train = []
for _ in range(len(train_it)):
    img, label = train_it.next()
    #print(img.shape)   #  (1,256,256,3)
    #img = np.expand_dims(img, axis=0)  # or axis=1
    #print(type(img))
    #print(np.ndim(img))
    img = np.squeeze(img, axis = -1)
    #print(img.shape)
    plt.title(label)
    #plt.text(200,220,label)
    plt.imshow(img[0])
    plt.show()
    x_train.append(img[0])
    y_train.append(label)

print(x_train)
print(y_train)

x_test = []
y_test = []
for _ in range(len(test_it)):
    img, label = test_it.next()
    #print(img.shape)   #  (1,256,256,3)
    #img = np.expand_dims(img, axis=0)  # or axis=1
    #print(type(img))
    #print(np.ndim(img))
    img = np.squeeze(img, axis = -1)
    #print(img.shape)
    plt.title(label)
    #plt.text(200,220,label)
    plt.imshow(img[0])
    plt.show()
    x_test.append(img[0])
    y_test.append(label)

print(x_test)
print(y_test)

x_val = []
y_val = []
for _ in range(len(val_it)):
    img, label = val_it.next()
    #print(img.shape)   #  (1,256,256,3)
    #img = np.expand_dims(img, axis=0)  # or axis=1
    #print(type(img))
    #print(np.ndim(img))
    img = np.squeeze(img, axis = -1)
    #print(img.shape)
    plt.title(label)
    #plt.text(200,220,label)
    plt.imshow(img[0])
    plt.show()
    x_val.append(img[0])
    y_val.append(label)

print(x_val)
print(y_val)

import keras
from keras.models import Sequential
from keras.layers import Dense, Conv2D , MaxPool2D , Flatten , Dropout 
#from keras.preprocessing.image import ImageDataGenerator

import tensorflow 
from tensorflow.keras.optimizers import Adam

x_train = np.expand_dims(x_train, axis = 3)
print(np.shape(x_train))

x_test = np.expand_dims(x_test, axis = 3)
print(np.shape(x_test))

x_val = np.expand_dims(x_val, axis = 3)
print(np.shape(x_val))

print(np.shape(x_train))
print(np.shape(y_train))
print(np.shape(x_test))
print(np.shape(y_test))

y_train = np.asarray(y_train).astype('float32').reshape((-1,1))
y_test = np.asarray(y_test).astype('float32').reshape((-1,1))

model = Sequential()
model.add(Conv2D(64,(4,4),padding="same", activation="relu", input_shape=(180,218,1)))
model.add(MaxPool2D())

model.add(Conv2D(32, (4,4), padding="same", activation="relu"))
model.add(MaxPool2D())

model.add(Conv2D(16, (4,4), padding="same", activation="relu"))
model.add(MaxPool2D())
model.add(Dropout(0.4))

model.add(Flatten())
model.add(Dense(64,activation="relu"))
model.add(Dense(1, activation="sigmoid"))

model.summary()

from tensorflow.keras import callbacks

class MyHistory(callbacks.Callback):
  def on_train_begin(self, logs=None):
    self.real_loss = []
  def on_epoch_end(self, epoch, logs=None):
    Ypred = self.model.predict(x_train)
    loss_value = self.model.loss(y_train,Ypred)
    self.real_loss.append(loss_value.numpy())

MyMonitor = MyHistory()

checkpointer = callbacks.ModelCheckpoint(filepath='BestModel.h5',monitor='val_accuracy',save_best_only=True)

#Monitor = model.fit(Xtrain,Ytrain,epochs=25,batch_size=25,validation_data=(Xtest,Ytest),)

opt = Adam(learning_rate=0.000002)
model.compile(optimizer = opt , loss = 'binary_crossentropy' , metrics = ['accuracy'])



x_train = np.expand_dims(x_train, axis = 3)
np.shape(x_train)
#y_train = np.expand_dims(y_train, axis = 1)
#np.shape(y_train)

x_test = np.expand_dims(x_test, axis = 3)
np.shape(x_test)

y_train = np.expand_dims(y_train, axis = 1)

y_test = np.expand_dims(y_test, axis = 1)

x_train = np.squeeze(x_train, axis = 1)

np.shape(x_test)

np.shape(y_test)

y_train = np.squeeze(y_train, axis = -1)

np.shape(y_train)
#np.shape(x_train)

np.shape(x_test)
y_test = np.expand_dims(y_test, axis = 1)
np.shape(y_train)

np.shape(y_test)

history = model.fit(x_train,y_train,epochs = 20 , validation_data = (x_test, y_test), callbacks=[checkpointer])

y_train = np.asarray(y_train).astype('float32').reshape((-1,1))
y_test = np.asarray(y_test).astype('float32').reshape((-1,1))

model.evaluate(x_test, y_test)

model.evaluate(x_val,y_val)
#np.shape(x_val[0])